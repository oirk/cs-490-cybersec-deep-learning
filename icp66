{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oirk/cs-490-cybersec-deep-learning/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB3F0JQBYPiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Bw5o7iYVr6",
        "colab_type": "code",
        "outputId": "56f53977-161d-4d0d-9584-d776a40ade1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = 'include pathe to where your notebook is located on the drive'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBdUnkntYhU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuyFmaFKYaQT",
        "colab_type": "code",
        "outputId": "77ce3189-962c-4421-e81f-ce44d3853101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to include pathe to where your notebook is located on the drive/data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:04, 40743593.72it/s]                               \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:04, 42081475.88it/s]                               \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dr1kXH8YosF",
        "colab_type": "code",
        "outputId": "ff9e96bb-6d6f-4902-cc46-24d6b47870e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx = indices[split3:-1]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzsPu490YxMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size =128 # pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnLMKhbYY1Rh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        \n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 220)\n",
        "        self.fc2 = nn.Linear(220, 184)\n",
        "        self.fc3 = nn.Linear(184, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNhjdQ05ZIuf",
        "colab_type": "code",
        "outputId": "114e9384-3bf2-476a-ad38-e9277d8d33db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a target model and train it\n",
        "\n",
        "target_model = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(target_model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# let the magic begin\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(target_train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = target_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        print((\"epoch: \",epoch + 1,\"data\", i + 1,\"loss: \", running_loss/98 ))\n",
        "        running_loss = 0.0\n",
        "        \n",
        "       \n",
        "        \n",
        "        \n",
        "\n",
        "print('Finished Training the Target model...')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('epoch: ', 1, 'data', 1, 'loss: ', 0.023564397072305485)\n",
            "('epoch: ', 1, 'data', 2, 'loss: ', 0.023473600951992735)\n",
            "('epoch: ', 1, 'data', 3, 'loss: ', 0.023465988587359994)\n",
            "('epoch: ', 1, 'data', 4, 'loss: ', 0.023508312750835807)\n",
            "('epoch: ', 1, 'data', 5, 'loss: ', 0.023425532847034688)\n",
            "('epoch: ', 1, 'data', 6, 'loss: ', 0.023526094397720024)\n",
            "('epoch: ', 1, 'data', 7, 'loss: ', 0.023410135385941486)\n",
            "('epoch: ', 1, 'data', 8, 'loss: ', 0.02353757011647127)\n",
            "('epoch: ', 1, 'data', 9, 'loss: ', 0.023468808251984264)\n",
            "('epoch: ', 1, 'data', 10, 'loss: ', 0.023452719863580197)\n",
            "('epoch: ', 1, 'data', 11, 'loss: ', 0.023410259460916325)\n",
            "('epoch: ', 1, 'data', 12, 'loss: ', 0.02337781263857472)\n",
            "('epoch: ', 1, 'data', 13, 'loss: ', 0.023477379156618704)\n",
            "('epoch: ', 1, 'data', 14, 'loss: ', 0.02349741118294852)\n",
            "('epoch: ', 1, 'data', 15, 'loss: ', 0.023556293273458675)\n",
            "('epoch: ', 1, 'data', 16, 'loss: ', 0.023508290855252013)\n",
            "('epoch: ', 1, 'data', 17, 'loss: ', 0.023572814707853357)\n",
            "('epoch: ', 1, 'data', 18, 'loss: ', 0.023475058224736427)\n",
            "('epoch: ', 1, 'data', 19, 'loss: ', 0.023542126830743283)\n",
            "('epoch: ', 1, 'data', 20, 'loss: ', 0.023524024048630073)\n",
            "('epoch: ', 1, 'data', 21, 'loss: ', 0.023521824758879994)\n",
            "('epoch: ', 1, 'data', 22, 'loss: ', 0.023574001935063576)\n",
            "('epoch: ', 1, 'data', 23, 'loss: ', 0.023401360122524962)\n",
            "('epoch: ', 1, 'data', 24, 'loss: ', 0.02356621683860312)\n",
            "('epoch: ', 1, 'data', 25, 'loss: ', 0.023493302111722986)\n",
            "('epoch: ', 1, 'data', 26, 'loss: ', 0.023441572578585878)\n",
            "('epoch: ', 1, 'data', 27, 'loss: ', 0.023540394646780833)\n",
            "('epoch: ', 1, 'data', 28, 'loss: ', 0.02345897470201765)\n",
            "('epoch: ', 1, 'data', 29, 'loss: ', 0.0234845511767329)\n",
            "('epoch: ', 1, 'data', 30, 'loss: ', 0.02347099781036377)\n",
            "('epoch: ', 1, 'data', 31, 'loss: ', 0.023484514684093242)\n",
            "('epoch: ', 1, 'data', 32, 'loss: ', 0.02341085550736408)\n",
            "('epoch: ', 1, 'data', 33, 'loss: ', 0.023510533936169684)\n",
            "('epoch: ', 1, 'data', 34, 'loss: ', 0.023543664387294223)\n",
            "('epoch: ', 1, 'data', 35, 'loss: ', 0.02355229124730947)\n",
            "('epoch: ', 1, 'data', 36, 'loss: ', 0.02344101789046307)\n",
            "('epoch: ', 1, 'data', 37, 'loss: ', 0.023537373056217115)\n",
            "('epoch: ', 1, 'data', 38, 'loss: ', 0.023537066518043985)\n",
            "('epoch: ', 1, 'data', 39, 'loss: ', 0.02345962670384621)\n",
            "('epoch: ', 1, 'data', 40, 'loss: ', 0.023580972029238333)\n",
            "('epoch: ', 1, 'data', 41, 'loss: ', 0.02351635572861652)\n",
            "('epoch: ', 1, 'data', 42, 'loss: ', 0.023526430130004883)\n",
            "('epoch: ', 1, 'data', 43, 'loss: ', 0.023568982980689223)\n",
            "('epoch: ', 1, 'data', 44, 'loss: ', 0.02349623611995152)\n",
            "('epoch: ', 1, 'data', 45, 'loss: ', 0.023523063075785736)\n",
            "('epoch: ', 1, 'data', 46, 'loss: ', 0.023490521372581015)\n",
            "('epoch: ', 1, 'data', 47, 'loss: ', 0.02352219211811922)\n",
            "('epoch: ', 1, 'data', 48, 'loss: ', 0.02354241147333262)\n",
            "('epoch: ', 1, 'data', 49, 'loss: ', 0.02352254731314523)\n",
            "('epoch: ', 1, 'data', 50, 'loss: ', 0.023527232968077367)\n",
            "('epoch: ', 1, 'data', 51, 'loss: ', 0.023483154725055307)\n",
            "('epoch: ', 1, 'data', 52, 'loss: ', 0.023473661773058832)\n",
            "('epoch: ', 1, 'data', 53, 'loss: ', 0.023487558170240754)\n",
            "('epoch: ', 1, 'data', 54, 'loss: ', 0.023501744075697297)\n",
            "('epoch: ', 1, 'data', 55, 'loss: ', 0.023502018986916055)\n",
            "('epoch: ', 1, 'data', 56, 'loss: ', 0.023524763632793814)\n",
            "('epoch: ', 1, 'data', 57, 'loss: ', 0.023490920358774613)\n",
            "('epoch: ', 1, 'data', 58, 'loss: ', 0.02349408062136903)\n",
            "('epoch: ', 1, 'data', 59, 'loss: ', 0.02348623227099983)\n",
            "('epoch: ', 1, 'data', 60, 'loss: ', 0.02345218950388383)\n",
            "('epoch: ', 1, 'data', 61, 'loss: ', 0.023545712840800384)\n",
            "('epoch: ', 1, 'data', 62, 'loss: ', 0.023469173178380848)\n",
            "('epoch: ', 1, 'data', 63, 'loss: ', 0.02351623651932697)\n",
            "('epoch: ', 1, 'data', 64, 'loss: ', 0.02352970230336092)\n",
            "('epoch: ', 1, 'data', 65, 'loss: ', 0.023489436324761838)\n",
            "('epoch: ', 1, 'data', 66, 'loss: ', 0.023475812405956035)\n",
            "('epoch: ', 1, 'data', 67, 'loss: ', 0.02350110910376724)\n",
            "('epoch: ', 1, 'data', 68, 'loss: ', 0.023506787358498087)\n",
            "('epoch: ', 1, 'data', 69, 'loss: ', 0.02347528447910231)\n",
            "('epoch: ', 1, 'data', 70, 'loss: ', 0.02352410919812261)\n",
            "('epoch: ', 1, 'data', 71, 'loss: ', 0.023476033794636628)\n",
            "('epoch: ', 1, 'data', 72, 'loss: ', 0.023492401959944745)\n",
            "('epoch: ', 1, 'data', 73, 'loss: ', 0.023513292779727857)\n",
            "('epoch: ', 1, 'data', 74, 'loss: ', 0.023546141021105707)\n",
            "('epoch: ', 1, 'data', 75, 'loss: ', 0.02350414772422946)\n",
            "('epoch: ', 1, 'data', 76, 'loss: ', 0.023478123606467734)\n",
            "('epoch: ', 1, 'data', 77, 'loss: ', 0.023503892275751854)\n",
            "('epoch: ', 1, 'data', 78, 'loss: ', 0.02353345861240309)\n",
            "('epoch: ', 1, 'data', 79, 'loss: ', 0.023515280412167917)\n",
            "('epoch: ', 1, 'data', 80, 'loss: ', 0.02342537714510548)\n",
            "('epoch: ', 1, 'data', 81, 'loss: ', 0.023540528453126246)\n",
            "('epoch: ', 1, 'data', 82, 'loss: ', 0.023476469273469885)\n",
            "('epoch: ', 1, 'data', 83, 'loss: ', 0.023486847780188735)\n",
            "('epoch: ', 1, 'data', 84, 'loss: ', 0.02349829917051354)\n",
            "('epoch: ', 1, 'data', 85, 'loss: ', 0.023493878695429588)\n",
            "('epoch: ', 1, 'data', 86, 'loss: ', 0.023465966691776197)\n",
            "('epoch: ', 1, 'data', 87, 'loss: ', 0.023449056002558494)\n",
            "('epoch: ', 1, 'data', 88, 'loss: ', 0.02351347037724086)\n",
            "('epoch: ', 1, 'data', 89, 'loss: ', 0.02345446421175587)\n",
            "('epoch: ', 1, 'data', 90, 'loss: ', 0.023471737394527514)\n",
            "('epoch: ', 1, 'data', 91, 'loss: ', 0.02355315977213334)\n",
            "('epoch: ', 1, 'data', 92, 'loss: ', 0.023470056300260583)\n",
            "('epoch: ', 1, 'data', 93, 'loss: ', 0.023504794860372737)\n",
            "('epoch: ', 1, 'data', 94, 'loss: ', 0.023518134136589205)\n",
            "('epoch: ', 1, 'data', 95, 'loss: ', 0.023485735971100475)\n",
            "('epoch: ', 1, 'data', 96, 'loss: ', 0.023500250310313945)\n",
            "('epoch: ', 1, 'data', 97, 'loss: ', 0.02353941907688063)\n",
            "('epoch: ', 1, 'data', 98, 'loss: ', 0.023512504538711235)\n",
            "('epoch: ', 2, 'data', 1, 'loss: ', 0.023507006314336037)\n",
            "('epoch: ', 2, 'data', 2, 'loss: ', 0.023468835013253347)\n",
            "('epoch: ', 2, 'data', 3, 'loss: ', 0.02348525183541434)\n",
            "('epoch: ', 2, 'data', 4, 'loss: ', 0.0234901491476565)\n",
            "('epoch: ', 2, 'data', 5, 'loss: ', 0.023420727982813)\n",
            "('epoch: ', 2, 'data', 6, 'loss: ', 0.023523194449288503)\n",
            "('epoch: ', 2, 'data', 7, 'loss: ', 0.023427277195210358)\n",
            "('epoch: ', 2, 'data', 8, 'loss: ', 0.023489660146285077)\n",
            "('epoch: ', 2, 'data', 9, 'loss: ', 0.023526661250056053)\n",
            "('epoch: ', 2, 'data', 10, 'loss: ', 0.02344271114894322)\n",
            "('epoch: ', 2, 'data', 11, 'loss: ', 0.023524114063807895)\n",
            "('epoch: ', 2, 'data', 12, 'loss: ', 0.02353008425965601)\n",
            "('epoch: ', 2, 'data', 13, 'loss: ', 0.023455573588001485)\n",
            "('epoch: ', 2, 'data', 14, 'loss: ', 0.023449608257838657)\n",
            "('epoch: ', 2, 'data', 15, 'loss: ', 0.02347592188387501)\n",
            "('epoch: ', 2, 'data', 16, 'loss: ', 0.02348280196287194)\n",
            "('epoch: ', 2, 'data', 17, 'loss: ', 0.023474106983262664)\n",
            "('epoch: ', 2, 'data', 18, 'loss: ', 0.023463672521163007)\n",
            "('epoch: ', 2, 'data', 19, 'loss: ', 0.023458561118768186)\n",
            "('epoch: ', 2, 'data', 20, 'loss: ', 0.02353796910266487)\n",
            "('epoch: ', 2, 'data', 21, 'loss: ', 0.02352871700209014)\n",
            "('epoch: ', 2, 'data', 22, 'loss: ', 0.02352065942725357)\n",
            "('epoch: ', 2, 'data', 23, 'loss: ', 0.023468630654471263)\n",
            "('epoch: ', 2, 'data', 24, 'loss: ', 0.02353051487280398)\n",
            "('epoch: ', 2, 'data', 25, 'loss: ', 0.023517827598416075)\n",
            "('epoch: ', 2, 'data', 26, 'loss: ', 0.023488645650902574)\n",
            "('epoch: ', 2, 'data', 27, 'loss: ', 0.02352561756056182)\n",
            "('epoch: ', 2, 'data', 28, 'loss: ', 0.02348429329541265)\n",
            "('epoch: ', 2, 'data', 29, 'loss: ', 0.023469727866503656)\n",
            "('epoch: ', 2, 'data', 30, 'loss: ', 0.023458935776535347)\n",
            "('epoch: ', 2, 'data', 31, 'loss: ', 0.0234746519400149)\n",
            "('epoch: ', 2, 'data', 32, 'loss: ', 0.02351810007679219)\n",
            "('epoch: ', 2, 'data', 33, 'loss: ', 0.02350264666031818)\n",
            "('epoch: ', 2, 'data', 34, 'loss: ', 0.023452749057691926)\n",
            "('epoch: ', 2, 'data', 35, 'loss: ', 0.023485911135770837)\n",
            "('epoch: ', 2, 'data', 36, 'loss: ', 0.023497895318634655)\n",
            "('epoch: ', 2, 'data', 37, 'loss: ', 0.023432374000549316)\n",
            "('epoch: ', 2, 'data', 38, 'loss: ', 0.023527653849854762)\n",
            "('epoch: ', 2, 'data', 39, 'loss: ', 0.023566569600786482)\n",
            "('epoch: ', 2, 'data', 40, 'loss: ', 0.023476741751846)\n",
            "('epoch: ', 2, 'data', 41, 'loss: ', 0.02345964373374472)\n",
            "('epoch: ', 2, 'data', 42, 'loss: ', 0.02347435999889763)\n",
            "('epoch: ', 2, 'data', 43, 'loss: ', 0.02347467140275605)\n",
            "('epoch: ', 2, 'data', 44, 'loss: ', 0.02345781423607651)\n",
            "('epoch: ', 2, 'data', 45, 'loss: ', 0.02347983389484639)\n",
            "('epoch: ', 2, 'data', 46, 'loss: ', 0.023488253963236908)\n",
            "('epoch: ', 2, 'data', 47, 'loss: ', 0.023523603166852678)\n",
            "('epoch: ', 2, 'data', 48, 'loss: ', 0.023497922079903737)\n",
            "('epoch: ', 2, 'data', 49, 'loss: ', 0.02345477561561429)\n",
            "('epoch: ', 2, 'data', 50, 'loss: ', 0.02348703754191496)\n",
            "('epoch: ', 2, 'data', 51, 'loss: ', 0.023495939313148965)\n",
            "('epoch: ', 2, 'data', 52, 'loss: ', 0.02343648063893221)\n",
            "('epoch: ', 2, 'data', 53, 'loss: ', 0.02355791597950215)\n",
            "('epoch: ', 2, 'data', 54, 'loss: ', 0.023499975399095183)\n",
            "('epoch: ', 2, 'data', 55, 'loss: ', 0.023481931005205427)\n",
            "('epoch: ', 2, 'data', 56, 'loss: ', 0.02347300490554498)\n",
            "('epoch: ', 2, 'data', 57, 'loss: ', 0.02348187018413933)\n",
            "('epoch: ', 2, 'data', 58, 'loss: ', 0.023533076656108)\n",
            "('epoch: ', 2, 'data', 59, 'loss: ', 0.023482373782566617)\n",
            "('epoch: ', 2, 'data', 60, 'loss: ', 0.02349740388442059)\n",
            "('epoch: ', 2, 'data', 61, 'loss: ', 0.023421275372407874)\n",
            "('epoch: ', 2, 'data', 62, 'loss: ', 0.02348771873785525)\n",
            "('epoch: ', 2, 'data', 63, 'loss: ', 0.023457074651912768)\n",
            "('epoch: ', 2, 'data', 64, 'loss: ', 0.023431033504252533)\n",
            "('epoch: ', 2, 'data', 65, 'loss: ', 0.023451325844745248)\n",
            "('epoch: ', 2, 'data', 66, 'loss: ', 0.023449299286822885)\n",
            "('epoch: ', 2, 'data', 67, 'loss: ', 0.023465528780100296)\n",
            "('epoch: ', 2, 'data', 68, 'loss: ', 0.02346831195208491)\n",
            "('epoch: ', 2, 'data', 69, 'loss: ', 0.023443044448385433)\n",
            "('epoch: ', 2, 'data', 70, 'loss: ', 0.023501863284986848)\n",
            "('epoch: ', 2, 'data', 71, 'loss: ', 0.023496822435028698)\n",
            "('epoch: ', 2, 'data', 72, 'loss: ', 0.023440565381731306)\n",
            "('epoch: ', 2, 'data', 73, 'loss: ', 0.02351766216511629)\n",
            "('epoch: ', 2, 'data', 74, 'loss: ', 0.023488302620089784)\n",
            "('epoch: ', 2, 'data', 75, 'loss: ', 0.023474698164025132)\n",
            "('epoch: ', 2, 'data', 76, 'loss: ', 0.023467628323301976)\n",
            "('epoch: ', 2, 'data', 77, 'loss: ', 0.02350591396798893)\n",
            "('epoch: ', 2, 'data', 78, 'loss: ', 0.02350935644033004)\n",
            "('epoch: ', 2, 'data', 79, 'loss: ', 0.023514854664705237)\n",
            "('epoch: ', 2, 'data', 80, 'loss: ', 0.0235531354437069)\n",
            "('epoch: ', 2, 'data', 81, 'loss: ', 0.023544910002727897)\n",
            "('epoch: ', 2, 'data', 82, 'loss: ', 0.023488560501410037)\n",
            "('epoch: ', 2, 'data', 83, 'loss: ', 0.023511504640384595)\n",
            "('epoch: ', 2, 'data', 84, 'loss: ', 0.023506536775705765)\n",
            "('epoch: ', 2, 'data', 85, 'loss: ', 0.02351146814774494)\n",
            "('epoch: ', 2, 'data', 86, 'loss: ', 0.023445197514125278)\n",
            "('epoch: ', 2, 'data', 87, 'loss: ', 0.023497094913404817)\n",
            "('epoch: ', 2, 'data', 88, 'loss: ', 0.023432602687757844)\n",
            "('epoch: ', 2, 'data', 89, 'loss: ', 0.02349046055151492)\n",
            "('epoch: ', 2, 'data', 90, 'loss: ', 0.023542659623282298)\n",
            "('epoch: ', 2, 'data', 91, 'loss: ', 0.02351881776537214)\n",
            "('epoch: ', 2, 'data', 92, 'loss: ', 0.023458548954554966)\n",
            "('epoch: ', 2, 'data', 93, 'loss: ', 0.02349569846172722)\n",
            "('epoch: ', 2, 'data', 94, 'loss: ', 0.02349661077771868)\n",
            "('epoch: ', 2, 'data', 95, 'loss: ', 0.02352977772148288)\n",
            "('epoch: ', 2, 'data', 96, 'loss: ', 0.023467299889545053)\n",
            "('epoch: ', 2, 'data', 97, 'loss: ', 0.023449019509918834)\n",
            "('epoch: ', 2, 'data', 98, 'loss: ', 0.023519676558825434)\n",
            "Finished Training the Target model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLz_1T0jZOwy",
        "colab_type": "code",
        "outputId": "116bd11c-5436-4a2a-dc40-2f19af9b6f6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Target Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in target_out_loader:\n",
        "        images, labels = data\n",
        "        outputs = target_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 11 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wik7LRDmZTOh",
        "colab_type": "code",
        "outputId": "50d3750b-8263-4bf3-c3ee-171669668a4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "# for the first ICP, your shadow model can have the same CNN architecture and hyperparameters\n",
        "\n",
        "shadow_model = Net()\n",
        "shadow_criterion =  nn.CrossEntropyLoss()\n",
        "shadow_optimizer = optim.SGD(target_model.parameters(), lr=0.001, momentum=0.9)\n",
        "shadow_model.train()\n",
        "# let the magic begin\n",
        "# let the magic begin\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(shadow_train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = shadow_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        print((\"epoch: \",epoch + 1,\"data\", i + 1,\"loss: \", running_loss/98 ))\n",
        "        running_loss = 0.0\n",
        "        \n",
        "\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('epoch: ', 1, 'data', 1, 'loss: ', 0.023501975195748464)\n",
            "('epoch: ', 1, 'data', 2, 'loss: ', 0.023468946924014966)\n",
            "('epoch: ', 1, 'data', 3, 'loss: ', 0.023464497254819285)\n",
            "('epoch: ', 1, 'data', 4, 'loss: ', 0.02348360236810178)\n",
            "('epoch: ', 1, 'data', 5, 'loss: ', 0.02346746775568748)\n",
            "('epoch: ', 1, 'data', 6, 'loss: ', 0.02343023309902269)\n",
            "('epoch: ', 1, 'data', 7, 'loss: ', 0.02357216757171008)\n",
            "('epoch: ', 1, 'data', 8, 'loss: ', 0.023556660632697905)\n",
            "('epoch: ', 1, 'data', 9, 'loss: ', 0.0235018219266619)\n",
            "('epoch: ', 1, 'data', 10, 'loss: ', 0.023490188073138803)\n",
            "('epoch: ', 1, 'data', 11, 'loss: ', 0.023540153795359085)\n",
            "('epoch: ', 1, 'data', 12, 'loss: ', 0.023520452635628835)\n",
            "('epoch: ', 1, 'data', 13, 'loss: ', 0.02347068640650535)\n",
            "('epoch: ', 1, 'data', 14, 'loss: ', 0.023454143076526875)\n",
            "('epoch: ', 1, 'data', 15, 'loss: ', 0.023562098036007006)\n",
            "('epoch: ', 1, 'data', 16, 'loss: ', 0.023541153693685726)\n",
            "('epoch: ', 1, 'data', 17, 'loss: ', 0.023481909109621633)\n",
            "('epoch: ', 1, 'data', 18, 'loss: ', 0.02348851184455716)\n",
            "('epoch: ', 1, 'data', 19, 'loss: ', 0.023481298466118013)\n",
            "('epoch: ', 1, 'data', 20, 'loss: ', 0.023443295031177754)\n",
            "('epoch: ', 1, 'data', 21, 'loss: ', 0.023532390594482422)\n",
            "('epoch: ', 1, 'data', 22, 'loss: ', 0.023520532919436087)\n",
            "('epoch: ', 1, 'data', 23, 'loss: ', 0.0235984738992185)\n",
            "('epoch: ', 1, 'data', 24, 'loss: ', 0.023542703414449886)\n",
            "('epoch: ', 1, 'data', 25, 'loss: ', 0.023504512650626048)\n",
            "('epoch: ', 1, 'data', 26, 'loss: ', 0.023506003983166754)\n",
            "('epoch: ', 1, 'data', 27, 'loss: ', 0.02352772683513408)\n",
            "('epoch: ', 1, 'data', 28, 'loss: ', 0.023474389193009357)\n",
            "('epoch: ', 1, 'data', 29, 'loss: ', 0.023501174790518626)\n",
            "('epoch: ', 1, 'data', 30, 'loss: ', 0.02349928447178432)\n",
            "('epoch: ', 1, 'data', 31, 'loss: ', 0.023468645251527125)\n",
            "('epoch: ', 1, 'data', 32, 'loss: ', 0.023468363041780432)\n",
            "('epoch: ', 1, 'data', 33, 'loss: ', 0.023475255284990584)\n",
            "('epoch: ', 1, 'data', 34, 'loss: ', 0.023536502098550603)\n",
            "('epoch: ', 1, 'data', 35, 'loss: ', 0.02354150645586909)\n",
            "('epoch: ', 1, 'data', 36, 'loss: ', 0.023596651700078224)\n",
            "('epoch: ', 1, 'data', 37, 'loss: ', 0.023476062988748356)\n",
            "('epoch: ', 1, 'data', 38, 'loss: ', 0.023519627901972557)\n",
            "('epoch: ', 1, 'data', 39, 'loss: ', 0.023539791301805144)\n",
            "('epoch: ', 1, 'data', 40, 'loss: ', 0.02354378116374113)\n",
            "('epoch: ', 1, 'data', 41, 'loss: ', 0.023465747735938246)\n",
            "('epoch: ', 1, 'data', 42, 'loss: ', 0.023488903532222827)\n",
            "('epoch: ', 1, 'data', 43, 'loss: ', 0.02349812887152847)\n",
            "('epoch: ', 1, 'data', 44, 'loss: ', 0.02351774244892354)\n",
            "('epoch: ', 1, 'data', 45, 'loss: ', 0.023516540624657457)\n",
            "('epoch: ', 1, 'data', 46, 'loss: ', 0.023547109292477976)\n",
            "('epoch: ', 1, 'data', 47, 'loss: ', 0.02357085383668238)\n",
            "('epoch: ', 1, 'data', 48, 'loss: ', 0.023503325423415825)\n",
            "('epoch: ', 1, 'data', 49, 'loss: ', 0.023543533013791453)\n",
            "('epoch: ', 1, 'data', 50, 'loss: ', 0.02341849949895119)\n",
            "('epoch: ', 1, 'data', 51, 'loss: ', 0.023539246345052913)\n",
            "('epoch: ', 1, 'data', 52, 'loss: ', 0.02346969867239193)\n",
            "('epoch: ', 1, 'data', 53, 'loss: ', 0.02352827909041424)\n",
            "('epoch: ', 1, 'data', 54, 'loss: ', 0.02349069897009402)\n",
            "('epoch: ', 1, 'data', 55, 'loss: ', 0.02352874133051658)\n",
            "('epoch: ', 1, 'data', 56, 'loss: ', 0.02342513386084109)\n",
            "('epoch: ', 1, 'data', 57, 'loss: ', 0.02356971769916768)\n",
            "('epoch: ', 1, 'data', 58, 'loss: ', 0.023506347013979544)\n",
            "('epoch: ', 1, 'data', 59, 'loss: ', 0.023560455867222378)\n",
            "('epoch: ', 1, 'data', 60, 'loss: ', 0.023525992218328982)\n",
            "('epoch: ', 1, 'data', 61, 'loss: ', 0.023522557044515804)\n",
            "('epoch: ', 1, 'data', 62, 'loss: ', 0.023477700291847696)\n",
            "('epoch: ', 1, 'data', 63, 'loss: ', 0.023511584924191843)\n",
            "('epoch: ', 1, 'data', 64, 'loss: ', 0.023596238116828764)\n",
            "('epoch: ', 1, 'data', 65, 'loss: ', 0.023527736566504653)\n",
            "('epoch: ', 1, 'data', 66, 'loss: ', 0.023511584924191843)\n",
            "('epoch: ', 1, 'data', 67, 'loss: ', 0.023517046655927385)\n",
            "('epoch: ', 1, 'data', 68, 'loss: ', 0.0235668810046449)\n",
            "('epoch: ', 1, 'data', 69, 'loss: ', 0.02345033324494654)\n",
            "('epoch: ', 1, 'data', 70, 'loss: ', 0.02351912916923056)\n",
            "('epoch: ', 1, 'data', 71, 'loss: ', 0.02350441533692029)\n",
            "('epoch: ', 1, 'data', 72, 'loss: ', 0.023479138101850237)\n",
            "('epoch: ', 1, 'data', 73, 'loss: ', 0.0235713817635361)\n",
            "('epoch: ', 1, 'data', 74, 'loss: ', 0.02352071781547702)\n",
            "('epoch: ', 1, 'data', 75, 'loss: ', 0.02356363802540059)\n",
            "('epoch: ', 1, 'data', 76, 'loss: ', 0.023505218174992775)\n",
            "('epoch: ', 1, 'data', 77, 'loss: ', 0.02347565913686947)\n",
            "('epoch: ', 1, 'data', 78, 'loss: ', 0.02348305741134955)\n",
            "('epoch: ', 1, 'data', 79, 'loss: ', 0.02353359485159115)\n",
            "('epoch: ', 1, 'data', 80, 'loss: ', 0.023494474741877342)\n",
            "('epoch: ', 1, 'data', 81, 'loss: ', 0.02347057936142902)\n",
            "('epoch: ', 1, 'data', 82, 'loss: ', 0.02348643176409663)\n",
            "('epoch: ', 1, 'data', 83, 'loss: ', 0.023519245945677465)\n",
            "('epoch: ', 1, 'data', 84, 'loss: ', 0.023524520348529428)\n",
            "('epoch: ', 1, 'data', 85, 'loss: ', 0.023492944483854333)\n",
            "('epoch: ', 1, 'data', 86, 'loss: ', 0.02353476991458815)\n",
            "('epoch: ', 1, 'data', 87, 'loss: ', 0.023533903822606922)\n",
            "('epoch: ', 1, 'data', 88, 'loss: ', 0.02349551843137157)\n",
            "('epoch: ', 1, 'data', 89, 'loss: ', 0.02341922935174436)\n",
            "('epoch: ', 1, 'data', 90, 'loss: ', 0.023507349345148826)\n",
            "('epoch: ', 1, 'data', 91, 'loss: ', 0.023550206301163654)\n",
            "('epoch: ', 1, 'data', 92, 'loss: ', 0.023481332525915027)\n",
            "('epoch: ', 1, 'data', 93, 'loss: ', 0.02356766194713359)\n",
            "('epoch: ', 1, 'data', 94, 'loss: ', 0.023514188065820812)\n",
            "('epoch: ', 1, 'data', 95, 'loss: ', 0.023516625774149993)\n",
            "('epoch: ', 1, 'data', 96, 'loss: ', 0.02356286924712512)\n",
            "('epoch: ', 1, 'data', 97, 'loss: ', 0.023428172481303314)\n",
            "('epoch: ', 1, 'data', 98, 'loss: ', 0.023566713138502473)\n",
            "('epoch: ', 2, 'data', 1, 'loss: ', 0.023519134034915845)\n",
            "('epoch: ', 2, 'data', 2, 'loss: ', 0.023550688004007145)\n",
            "('epoch: ', 2, 'data', 3, 'loss: ', 0.023554317805231834)\n",
            "('epoch: ', 2, 'data', 4, 'loss: ', 0.023494392025227448)\n",
            "('epoch: ', 2, 'data', 5, 'loss: ', 0.023478206323117624)\n",
            "('epoch: ', 2, 'data', 6, 'loss: ', 0.02349169400273537)\n",
            "('epoch: ', 2, 'data', 7, 'loss: ', 0.02348108194312271)\n",
            "('epoch: ', 2, 'data', 8, 'loss: ', 0.02351632653450479)\n",
            "('epoch: ', 2, 'data', 9, 'loss: ', 0.023521163025680854)\n",
            "('epoch: ', 2, 'data', 10, 'loss: ', 0.023556580348890657)\n",
            "('epoch: ', 2, 'data', 11, 'loss: ', 0.02354389794018804)\n",
            "('epoch: ', 2, 'data', 12, 'loss: ', 0.023514214827089895)\n",
            "('epoch: ', 2, 'data', 13, 'loss: ', 0.023504704845194915)\n",
            "('epoch: ', 2, 'data', 14, 'loss: ', 0.023581059611573512)\n",
            "('epoch: ', 2, 'data', 15, 'loss: ', 0.023514667335821658)\n",
            "('epoch: ', 2, 'data', 16, 'loss: ', 0.023490764656845405)\n",
            "('epoch: ', 2, 'data', 17, 'loss: ', 0.023492333840350717)\n",
            "('epoch: ', 2, 'data', 18, 'loss: ', 0.023503931201234157)\n",
            "('epoch: ', 2, 'data', 19, 'loss: ', 0.023471219199044362)\n",
            "('epoch: ', 2, 'data', 20, 'loss: ', 0.023520250709689394)\n",
            "('epoch: ', 2, 'data', 21, 'loss: ', 0.023561808527732382)\n",
            "('epoch: ', 2, 'data', 22, 'loss: ', 0.023503712245396206)\n",
            "('epoch: ', 2, 'data', 23, 'loss: ', 0.023500644430822254)\n",
            "('epoch: ', 2, 'data', 24, 'loss: ', 0.02346392553679797)\n",
            "('epoch: ', 2, 'data', 25, 'loss: ', 0.02350774589849978)\n",
            "('epoch: ', 2, 'data', 26, 'loss: ', 0.023523218777714943)\n",
            "('epoch: ', 2, 'data', 27, 'loss: ', 0.023478685593118474)\n",
            "('epoch: ', 2, 'data', 28, 'loss: ', 0.023475038761995276)\n",
            "('epoch: ', 2, 'data', 29, 'loss: ', 0.0235219804608092)\n",
            "('epoch: ', 2, 'data', 30, 'loss: ', 0.02350230362950539)\n",
            "('epoch: ', 2, 'data', 31, 'loss: ', 0.023500466833309253)\n",
            "('epoch: ', 2, 'data', 32, 'loss: ', 0.023492363034462442)\n",
            "('epoch: ', 2, 'data', 33, 'loss: ', 0.023519370020652304)\n",
            "('epoch: ', 2, 'data', 34, 'loss: ', 0.023539959167947575)\n",
            "('epoch: ', 2, 'data', 35, 'loss: ', 0.02350325973666444)\n",
            "('epoch: ', 2, 'data', 36, 'loss: ', 0.023535030228751048)\n",
            "('epoch: ', 2, 'data', 37, 'loss: ', 0.023518812899686853)\n",
            "('epoch: ', 2, 'data', 38, 'loss: ', 0.023460684990396306)\n",
            "('epoch: ', 2, 'data', 39, 'loss: ', 0.023562022617885044)\n",
            "('epoch: ', 2, 'data', 40, 'loss: ', 0.023568467218048717)\n",
            "('epoch: ', 2, 'data', 41, 'loss: ', 0.023487665215317085)\n",
            "('epoch: ', 2, 'data', 42, 'loss: ', 0.02345697490536437)\n",
            "('epoch: ', 2, 'data', 43, 'loss: ', 0.023482055080180267)\n",
            "('epoch: ', 2, 'data', 44, 'loss: ', 0.023571758854145905)\n",
            "('epoch: ', 2, 'data', 45, 'loss: ', 0.023511784417288645)\n",
            "('epoch: ', 2, 'data', 46, 'loss: ', 0.02346678655974719)\n",
            "('epoch: ', 2, 'data', 47, 'loss: ', 0.023517676762172153)\n",
            "('epoch: ', 2, 'data', 48, 'loss: ', 0.023524493587260345)\n",
            "('epoch: ', 2, 'data', 49, 'loss: ', 0.023522077774514958)\n",
            "('epoch: ', 2, 'data', 50, 'loss: ', 0.023484456295869788)\n",
            "('epoch: ', 2, 'data', 51, 'loss: ', 0.023534898855248277)\n",
            "('epoch: ', 2, 'data', 52, 'loss: ', 0.023511295415917222)\n",
            "('epoch: ', 2, 'data', 53, 'loss: ', 0.023567503812361737)\n",
            "('epoch: ', 2, 'data', 54, 'loss: ', 0.023482972261857013)\n",
            "('epoch: ', 2, 'data', 55, 'loss: ', 0.023490487312784)\n",
            "('epoch: ', 2, 'data', 56, 'loss: ', 0.02346744342726104)\n",
            "('epoch: ', 2, 'data', 57, 'loss: ', 0.02346766724878428)\n",
            "('epoch: ', 2, 'data', 58, 'loss: ', 0.023473394160368005)\n",
            "('epoch: ', 2, 'data', 59, 'loss: ', 0.023475094717376088)\n",
            "('epoch: ', 2, 'data', 60, 'loss: ', 0.02348859212836441)\n",
            "('epoch: ', 2, 'data', 61, 'loss: ', 0.023501695418844417)\n",
            "('epoch: ', 2, 'data', 62, 'loss: ', 0.023476430347987583)\n",
            "('epoch: ', 2, 'data', 63, 'loss: ', 0.023539983496374012)\n",
            "('epoch: ', 2, 'data', 64, 'loss: ', 0.02348681372039172)\n",
            "('epoch: ', 2, 'data', 65, 'loss: ', 0.023498476768026546)\n",
            "('epoch: ', 2, 'data', 66, 'loss: ', 0.023587348509807975)\n",
            "('epoch: ', 2, 'data', 67, 'loss: ', 0.023594408619160553)\n",
            "('epoch: ', 2, 'data', 68, 'loss: ', 0.023498486499397123)\n",
            "('epoch: ', 2, 'data', 69, 'loss: ', 0.023515623442980707)\n",
            "('epoch: ', 2, 'data', 70, 'loss: ', 0.023541499157341158)\n",
            "('epoch: ', 2, 'data', 71, 'loss: ', 0.023555991600970834)\n",
            "('epoch: ', 2, 'data', 72, 'loss: ', 0.023513660138967087)\n",
            "('epoch: ', 2, 'data', 73, 'loss: ', 0.023457378757243255)\n",
            "('epoch: ', 2, 'data', 74, 'loss: ', 0.023552802144264688)\n",
            "('epoch: ', 2, 'data', 75, 'loss: ', 0.023473569325038364)\n",
            "('epoch: ', 2, 'data', 76, 'loss: ', 0.023454717227390835)\n",
            "('epoch: ', 2, 'data', 77, 'loss: ', 0.023509093693324497)\n",
            "('epoch: ', 2, 'data', 78, 'loss: ', 0.02345851976044324)\n",
            "('epoch: ', 2, 'data', 79, 'loss: ', 0.023556687393966987)\n",
            "('epoch: ', 2, 'data', 80, 'loss: ', 0.023586750030517578)\n",
            "('epoch: ', 2, 'data', 81, 'loss: ', 0.023501206417472994)\n",
            "('epoch: ', 2, 'data', 82, 'loss: ', 0.023569783385919064)\n",
            "('epoch: ', 2, 'data', 83, 'loss: ', 0.023497501198126346)\n",
            "('epoch: ', 2, 'data', 84, 'loss: ', 0.023439477901069487)\n",
            "('epoch: ', 2, 'data', 85, 'loss: ', 0.02354287371343496)\n",
            "('epoch: ', 2, 'data', 86, 'loss: ', 0.023533993837784747)\n",
            "('epoch: ', 2, 'data', 87, 'loss: ', 0.02346671844015316)\n",
            "('epoch: ', 2, 'data', 88, 'loss: ', 0.023532047563669632)\n",
            "('epoch: ', 2, 'data', 89, 'loss: ', 0.023596534923631316)\n",
            "('epoch: ', 2, 'data', 90, 'loss: ', 0.023557918412344798)\n",
            "('epoch: ', 2, 'data', 91, 'loss: ', 0.023415577654935876)\n",
            "('epoch: ', 2, 'data', 92, 'loss: ', 0.02344435331772785)\n",
            "('epoch: ', 2, 'data', 93, 'loss: ', 0.023566934527183066)\n",
            "('epoch: ', 2, 'data', 94, 'loss: ', 0.02346957946310238)\n",
            "('epoch: ', 2, 'data', 95, 'loss: ', 0.023468470086856763)\n",
            "('epoch: ', 2, 'data', 96, 'loss: ', 0.02349612907487519)\n",
            "('epoch: ', 2, 'data', 97, 'loss: ', 0.02349772258680694)\n",
            "('epoch: ', 2, 'data', 98, 'loss: ', 0.02351334873510867)\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j93bSlbdZX_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def freeze_model(model):\n",
        "    model.eval()\n",
        "    for params in model.parameters():\n",
        "        params.requires_grad = False\n",
        "        \n",
        "        \n",
        "freeze_model(shadow_model)\n",
        " \n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0#np.zeros(1)\n",
        "labels_1 = 1#np.ones(1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        \n",
        "        images = images\n",
        "        labels = labels\n",
        "        logps = shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        \n",
        "        images = images\n",
        "        labels = labels\n",
        "        logps = shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDgbd0XjZcZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "dacbda56-4609-48b1-d67b-b4899b5f18f2"
      },
      "source": [
        "# create the Attack Model: A NN binary classifier {0, 1}\n",
        "# the input to this model is the propability distribution vector of size 10\n",
        "# and the output is either 0 (input was not included in training) or 1\n",
        "\n",
        "from torch.autograd import Variable\n",
        "attack_model = nn.Sequential(nn.Linear(10, 20),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(20, 26),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(26, 16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(16, 8),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(8, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "attack_model = attack_model\n",
        "attack_criterion = nn.CrossEntropyLoss()\n",
        "attack_optimizer = optim.Adam(attack_model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for outputs, labels in train_loader:\n",
        "       \n",
        "        outputs = outputs.float()\n",
        "        labels = labels.long()\n",
        "        attack_optimizer.zero_grad()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        loss = attack_criterion(pred, labels)\n",
        "        loss.backward()\n",
        "        attack_optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(predictions)}\")\n",
        "        \n",
        "torch.save(attack_model.state_dict(), project_path+'/attack_checkpoint.pth')\n",
        "print('Finished Training the Attack model')  \n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.07088064964936704\n",
            "Training loss: 0.07075232328200827\n",
            "Training loss: 0.07075854041138474\n",
            "Training loss: 0.0707769019871342\n",
            "Training loss: 0.07079235357897622\n",
            "Finished Training the Attack model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VschPIPH3X96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "219adba8-edef-4d6f-e5fd-9e6e5ef6f386"
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/shadow.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    predictionsList = pickle.load(filehandle)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-59cc4ec60c31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/data/shadow.data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfilehandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# read the data as binary data stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpredictionsList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilehandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'include pathe to where your notebook is located on the drive/data/shadow.data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPFnOG3-1sqs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f45231f5-407a-4636-ae55-4d55d2ba48b8"
      },
      "source": [
        "total_size = len(predictions)\n",
        "split1 = total_size // 4\n",
        "split1 = total_size - split1 \n",
        "split2 = split1*2\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "train_idx = indices[:] \n",
        "test_idx = indices[split1:] \n",
        "print(f'No.of train date {len(train_idx)} and No.of test data {len(test_idx)}')\n",
        "batch_size = 10 # pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "train_sampler = SubsetRandomSampler(train_idx) # Pytorch function\n",
        "train_loader = torch.utils.data.DataLoader(predictions, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "test_sampler = SubsetRandomSampler(test_idx) # Pytorch function\n",
        "test_loader = torch.utils.data.DataLoader(predictions, batch_size=batch_size, sampler=test_sampler)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of train date 196 and No.of test data 49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faPHEh9jZgFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "# and then input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "\n",
        "\n",
        "predictions = []\n",
        "label_size = (1,1)\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_train_loader:\n",
        "        \n",
        "        images = images\n",
        "        labels = labels\n",
        "        logps = target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        \n",
        "        images = images\n",
        "        labels = labels\n",
        "        logps = target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/target.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)\n",
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    testloader = pickle.load(filehandle)\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF2OZWIx2gNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    validation = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DazrsmyY2oIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1 # pick your own\n",
        "\n",
        "validation_sampler = SubsetRandomSampler(indices[6250:18250]) # randomly picking 5000 data items\n",
        "validation_loader = torch.utils.data.DataLoader(validation, batch_size=batch_size, sampler=validation_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXWyoVXn2qfg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e4ab15c-5402-4e25-ecc5-e950c75539c7"
      },
      "source": [
        "#input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "total = 0\n",
        "tp = 0\n",
        "tn = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "with torch.no_grad():\n",
        "    for outputs, labels in validation_loader:\n",
        "        \n",
        "        outputs = outputs.float()\n",
        "        labels = labels.long()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        predicted = torch.argmax(pred.data)\n",
        "        \n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.item() == labels.item())\n",
        "        tp += ((predicted.item() == labels.item()) and (predicted.item() == 1))\n",
        "        tn += ((predicted.item() == labels.item()) and (predicted.item() == 0))\n",
        "        fp += ((predicted.item() != labels.item()) and (predicted.item() == 1))\n",
        "        fn += ((predicted.item() != labels.item()) and (predicted.item() == 0))\n",
        "        \n",
        "incorrect = total- correct\n",
        "print(f'TP : {tp}, TN : {tn}, FP : {fp}, FN : {fn}')\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP : 0, TN : 0, FP : 0, FN : 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
